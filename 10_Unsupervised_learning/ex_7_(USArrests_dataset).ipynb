{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_Unsupervised learning,_ex_7_(USArrests dataset)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYjDE+C4MIm8cnFNT7kz/c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWPA6J4uLVeL"
      },
      "source": [
        "All instructions are provided for R. I am going to reproduce them in Python as best as I can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3r7_JfM7M9m"
      },
      "source": [
        "# Preface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QyJDa9OnHCt"
      },
      "source": [
        "From the textbook, p. 416:\n",
        "> In the chapter, we mentioned the use of correlation-based distance and Euclidean distance as dissimilarity measures for hierarchical clustering. It turns out that these two measures are almost equivalent: if each observation has been centered to have mean zero and standard deviation one, and if we let $r_{ij}$ denote the correlation between the i-th and j-th observations, then the quantity $1 âˆ’ r_{ij}$ is proportional to the squared Euclidean distance between the i-th and j-th observations. On the `USArrests` data, show that this proportionality holds. <br><br>*Hint: The Euclidean distance can be calculated using the `dist()` function, and correlations can be calculated using the `cor()` function.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIFrLpV4mBBB"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import pdist\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "sns.set()\n",
        "%matplotlib inline"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6nDKK9el2Wo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "2b154cfa-5184-4d1b-ab56-b49236ca2313"
      },
      "source": [
        "usarrests = pd.read_csv(\n",
        "                        'https://raw.githubusercontent.com'\n",
        "                        '/dsnair/ISLR/master/data/csv/USArrests.csv'\n",
        "                       ).set_index('State')\n",
        "usarrests.head(3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Murder</th>\n",
              "      <th>Assault</th>\n",
              "      <th>UrbanPop</th>\n",
              "      <th>Rape</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>State</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alabama</th>\n",
              "      <td>13.2</td>\n",
              "      <td>236</td>\n",
              "      <td>58</td>\n",
              "      <td>21.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>10.0</td>\n",
              "      <td>263</td>\n",
              "      <td>48</td>\n",
              "      <td>44.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arizona</th>\n",
              "      <td>8.1</td>\n",
              "      <td>294</td>\n",
              "      <td>80</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Murder  Assault  UrbanPop  Rape\n",
              "State                                   \n",
              "Alabama    13.2      236        58  21.2\n",
              "Alaska     10.0      263        48  44.5\n",
              "Arizona     8.1      294        80  31.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e26bP5W0yKqr"
      },
      "source": [
        "It took me a while to get it, but when you use SciPy's `pdist()` with `metric='correlation'`, the distances are **already** $1 - r_{ij}$. [Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDC7kYb1Yu1O",
        "outputId": "6e7e0120-6875-465f-cb60-a3c982717a65"
      },
      "source": [
        "scaled = StandardScaler().fit_transform(usarrests.T).T\n",
        "euclidian_dist = pdist(scaled, metric='euclidean')**2\n",
        "correlation_dist = pdist(scaled, metric='correlation')\n",
        "\n",
        "coefs = euclidian_squares / correlation_dist\n",
        "print(coefs)\n",
        "(abs(coefs - coefs[0]) < 1e-10).all()  # all equal up to numeric precision"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8. 8. 8. ... 8. 8. 8.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltvQUGme1VSv"
      },
      "source": [
        "The explanation of where those 8's come from, borrowed from [this thread](https://stackoverflow.com/questions/40823581/squared-euclidean-distance-and-correlation-between-two-normalized-variables-a-p) on StackOverflow.\n",
        "\n",
        "1. All **observations** are standardized. This means that $ \\bar{x}_i = 0 $, and $\\text{var} (x_i) = 1$, and $ x_i^T x_i = p $ where $x_i$ is the i-th observation and $p$ is the number of predictors.\n",
        "1. Covariation:\n",
        "$$ \\text{cov}(x_i, x_j) = \\frac{(x_i - \\bar{x}_i)^T (x_j - \\bar{x}_j)}{p} = \\frac{x_i^T x_j}{p}$$\n",
        "1. Correlation:\n",
        "$$ r_{ij} = \\frac{\\text{cov}(x_i, x_j)}{\\sqrt{\\text{var} (x_i) \\cdot \\text{var} (x_j)}} = \\text{cov}(x_i, x_j) = \\frac{x_i^T x_j}{p} $$\n",
        "1. Square of the Euclidean distance is:\n",
        "$$\n",
        "\\begin{align}\n",
        "  ||x_i - x_j||^2 &= (x_i - x_j)^T (x_i - x_j) \\\\\n",
        "                  &= x_i^T x_i + x_j^T x_j - 2 x_i^T x_j^T \\\\\n",
        "                  &= p + p - 2p \\cdot r_{ij} \\\\\n",
        "                  &= 2p \\cdot (1 - r_{ij})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "This means, that squared Euclidean distance is proportional to $1 - r_{ij}$. The coefficient in this proportion is $2p$ which is twice the number of predictors. There are four predictors in the `USArrests` dataset; so $2p = 8$, and that's what we've seen above: two hundred 8's.\n"
      ]
    }
  ]
}