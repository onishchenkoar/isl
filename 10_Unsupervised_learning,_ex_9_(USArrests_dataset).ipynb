{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_Unsupervised learning,_ex_9_(USArrests dataset)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPijTbExrGeFOnf2D/p8wkH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWPA6J4uLVeL"
      },
      "source": [
        "All instructions are provided for R. I am going to reproduce them in Python as best as I can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3r7_JfM7M9m"
      },
      "source": [
        "# Preface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ3UkKUL_6RR"
      },
      "source": [
        "From the textbook, p. 416:\n",
        "> Consider the `USArrests` data. We will now perform hierarchical clustering on the states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV3yn0CDmYAE"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "\n",
        "sns.set()\n",
        "%matplotlib inline"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuzz2-ASFQwZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "b556a814-0d2f-462d-d2a8-0590703a8b2d"
      },
      "source": [
        "usarrests = pd.read_csv(\n",
        "                        'https://raw.githubusercontent.com'\n",
        "                        '/dsnair/ISLR/master/data/csv/USArrests.csv'\n",
        "                       ).set_index('State')\n",
        "usarrests.head(3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Murder</th>\n",
              "      <th>Assault</th>\n",
              "      <th>UrbanPop</th>\n",
              "      <th>Rape</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>State</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alabama</th>\n",
              "      <td>13.2</td>\n",
              "      <td>236</td>\n",
              "      <td>58</td>\n",
              "      <td>21.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>10.0</td>\n",
              "      <td>263</td>\n",
              "      <td>48</td>\n",
              "      <td>44.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arizona</th>\n",
              "      <td>8.1</td>\n",
              "      <td>294</td>\n",
              "      <td>80</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Murder  Assault  UrbanPop  Rape\n",
              "State                                   \n",
              "Alabama    13.2      236        58  21.2\n",
              "Alaska     10.0      263        48  44.5\n",
              "Arizona     8.1      294        80  31.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT02YI14FRKp"
      },
      "source": [
        "# (a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRCNLIktHnjg"
      },
      "source": [
        "From the textbook, p. 416:\n",
        "> Using hierarchical clustering with complete linkage and Euclidean distance, cluster the states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNKlVP0dHriw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a39f705-f024-425e-d774-58bae9a24c12"
      },
      "source": [
        "hclust = AgglomerativeClustering(n_clusters=3, linkage='complete')\n",
        "hclust.fit(usarrests)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
              "                        connectivity=None, distance_threshold=None,\n",
              "                        linkage='complete', memory=None, n_clusters=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoZ89wzOHsCQ"
      },
      "source": [
        "# (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz3amm1BHvUb"
      },
      "source": [
        "From the textbook, p. 416:\n",
        "> Cut the dendrogram at a height that results in three distinct clusters. Which states belong to which clusters?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVTfWgwspoul"
      },
      "source": [
        "In `sklearn` you have to define the number of clusters beforehand (`n_clusters=3` above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWHkUHs6HwMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e6ded16-7ee6-465a-ef98-1958d715e4ac"
      },
      "source": [
        "clustering_not_scaled = pd.Series(hclust.labels_, index=usarrests.index)\n",
        "clustering_not_scaled.sort_values()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State\n",
              "Missouri          0\n",
              "Wisconsin         0\n",
              "Montana           0\n",
              "Nebraska          0\n",
              "New Hampshire     0\n",
              "New Jersey        0\n",
              "North Dakota      0\n",
              "Ohio              0\n",
              "Oklahoma          0\n",
              "Oregon            0\n",
              "Pennsylvania      0\n",
              "Rhode Island      0\n",
              "South Dakota      0\n",
              "Utah              0\n",
              "Vermont           0\n",
              "Virginia          0\n",
              "Washington        0\n",
              "West Virginia     0\n",
              "Minnesota         0\n",
              "Massachusetts     0\n",
              "Wyoming           0\n",
              "Hawaii            0\n",
              "Maine             0\n",
              "Arkansas          0\n",
              "Kentucky          0\n",
              "Kansas            0\n",
              "Iowa              0\n",
              "Indiana           0\n",
              "Connecticut       0\n",
              "Delaware          0\n",
              "Idaho             0\n",
              "Alaska            1\n",
              "Tennessee         1\n",
              "South Carolina    1\n",
              "Georgia           1\n",
              "Alabama           1\n",
              "North Carolina    1\n",
              "Louisiana         1\n",
              "Mississippi       1\n",
              "Illinois          2\n",
              "Florida           2\n",
              "New York          2\n",
              "New Mexico        2\n",
              "Nevada            2\n",
              "Texas             2\n",
              "Colorado          2\n",
              "California        2\n",
              "Arizona           2\n",
              "Maryland          2\n",
              "Michigan          2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5IKTx5oHwhZ"
      },
      "source": [
        "# (c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDNTCjGtH2ny"
      },
      "source": [
        "From the textbook, p. 416:\n",
        "> Hierarchically cluster the states using complete linkage and Euclidean distance, after scaling the variables to have standard deviation one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kldBhdEH6BR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2a81f8-6dc3-487e-de78-2fdfb8a31e73"
      },
      "source": [
        "x = StandardScaler().fit_transform(usarrests)\n",
        "hclust.fit(x)\n",
        "clustering_scaled = pd.Series(hclust.labels_, index=usarrests.index)\n",
        "clustering_scaled.sort_values()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State\n",
              "Missouri          0\n",
              "Wisconsin         0\n",
              "Montana           0\n",
              "Nebraska          0\n",
              "New Hampshire     0\n",
              "New Jersey        0\n",
              "North Dakota      0\n",
              "Ohio              0\n",
              "Oklahoma          0\n",
              "Oregon            0\n",
              "Pennsylvania      0\n",
              "Rhode Island      0\n",
              "South Dakota      0\n",
              "Utah              0\n",
              "Vermont           0\n",
              "Virginia          0\n",
              "Washington        0\n",
              "West Virginia     0\n",
              "Minnesota         0\n",
              "Massachusetts     0\n",
              "Wyoming           0\n",
              "Hawaii            0\n",
              "Maine             0\n",
              "Arkansas          0\n",
              "Kentucky          0\n",
              "Kansas            0\n",
              "Iowa              0\n",
              "Indiana           0\n",
              "Connecticut       0\n",
              "Delaware          0\n",
              "Idaho             0\n",
              "Alaska            1\n",
              "Tennessee         1\n",
              "South Carolina    1\n",
              "Georgia           1\n",
              "Alabama           1\n",
              "North Carolina    1\n",
              "Louisiana         1\n",
              "Mississippi       1\n",
              "Illinois          2\n",
              "Florida           2\n",
              "New York          2\n",
              "New Mexico        2\n",
              "Nevada            2\n",
              "Texas             2\n",
              "Colorado          2\n",
              "California        2\n",
              "Arizona           2\n",
              "Maryland          2\n",
              "Michigan          2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNLX9ZqjH6VY"
      },
      "source": [
        "# (d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LwZ8Cb2H_MH"
      },
      "source": [
        "From the textbook, p. 416:\n",
        "> What effect does scaling the variables have on the hierarchical clustering obtained? In your opinion, should the variables be scaled before the inter-observation dissimilarities are computed? Provide a justification for your answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIFrLpV4mBBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19a5424-f2d1-49ba-abfd-7c6b87717e3b"
      },
      "source": [
        "(clustering_not_scaled == clustering_scaled).all()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubrYnjzbCADm"
      },
      "source": [
        "In this case, scaling does not matter. I think that, in general, a feature matrix should be scaled before the inter-observation dissimilarities are computed. If the predictors have different scales, the ones with large absolute differences will dominate the ones with low, regardless of their relative differences. Relative differences should be important for determining how close or far apart any two points in the dataset."
      ]
    }
  ]
}